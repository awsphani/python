https://www.youtube.com/watch?v=PvbT-l0mweY&list=PLf0swTFhTI8otgadSFlL44X_ISa0jvhJQ&index=7
https://www.youtube.com/watch?v=EGQjqcOIjIM&index=8&list=PLf0swTFhTI8o2V96xr0ayFWKfFJ2PvxHM
https://www.youtube.com/watch?v=8N1VZ6muG8U&index=12&list=PLf0swTFhTI8q0x0V1E6We5zBQ9UazHFY0
https://www.youtube.com/watch?v=aLt6n6shqJw&list=PLf0swTFhTI8pronNK7Gm-isKX7tdNb0Go


REPL: read evaluate print loop
print ("Hello World")    

sh-4.2$ python                                                                  
Python 2.7.12 (default, Sep  1 2016, 22:14:00)                                  
[GCC 4.8.3 20140911 (Red Hat 4.8.3-9)] on linux2                                
Type "help", "copyright", "credits" or "license" for more information.          
>>> print ("Hello World")                                                       
Hello World    

>>l = range (1,20)                                                                                                                                                                                                                                                                         
>>> l                                                                                                                                                                                                                                                                                        
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]

>>> res=0                                                                                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                                      
>>> for i in l:                                                                                                                                                                                                                                                                              
...  res+=i                                                                                                                                                                                                                                                                                  
...                                                                                                                                                                                                                                                                                          
>>> res                                                                                                                                                                                                                                                                                      
190                                                                                                                                                                                                                                                                                          


def sum(func,lb,ub):
  tot=0
  while(lb<=ub):
    tot+=func(lb)
    lb+=1
   return tot
   
 def id(i):
  return i
  
 def sqr(i)
   return i*i
  
  sum(id,1,10)
  sum(sqr,1,10)
  
  
  sum(lambda i: i*i, 1,10)
  
  lists:
  
  l = [1,2,3,1,2,7,8]
  
  l[0]=1
  l[1]=2
  l[-1] last elem
  l[2:5]
  s= set(l)
  
  removes duplicates and sets cannot do s[0] s[1]...set obj doesnot support indexing
  
  help(l)
  help(s)
  
  >>> l =[1,2,1,2,5,6,7]                                                                              
>>> l                                                                                               
[1, 2, 1, 2, 5, 6, 7]                                                                               
>>> s= set(l)                                                                                       
>>> s                                                                                               
set([1, 2, 5, 6, 7])                                                                                
>>> l1= [8,9,10]                                                                                    
>>>                                                                                                 
>>> l.append(3,4,5)                                                                                 
Traceback (most recent call last):                                                                  
  File "<stdin>", line 1, in <module>                                                               
TypeError: append() takes exactly one argument (3 given)                                            
>>> l.append(3)                                                                                     
>>> l                                                                                               
[1, 2, 1, 2, 5, 6, 7, 3]                                                                            
>>> l.append(l1)                                                                                    
>>> l                                                                                               
[1, 2, 1, 2, 5, 6, 7, 3, [8, 9, 10]]                                                                
>>> l.extend(l1)                                                                                    
>>> l                                                                                               
[1, 2, 1, 2, 5, 6, 7, 3, [8, 9, 10], 8, 9, 10]                                                      
>>>                                                                                                 
    
 l.append(object)  -- append object to end
 l.extend(iterable) --extend list by appending elems from iterable
 >>> l[2:5]                                                                                          
[1, 2, 5] 
l[2:5][0]
1

>>> d= {1:"hello",2:"world"} 
>>> d[1]="folks"                                                                                    
>>> d                                                                                               
{1: 'folks', 2: 'world'}  
>>> d.keys()                                                                                        
[1, 2]                                                                                              
>>> d.values()                                                                                      
['folks', 'world']                                                                                  
>>> d.items()                                                                                       
[(1, 'folks'), (2, 'world')]                                                                        
>>> type(d.items())                                                                                 
<type 'list'>  

 map filter reduce
 
 map(function, sequence[, sequence, ...]) -> list                                                
                                                                                                    
    Return a list of the results of applying the function to the items of                           
    the argument sequence(s).  If more than one sequence is given, the                              
    function is called with an argument list consisting of the corresponding                        
    item of each sequence, substituting None for missing values when not all                        
    sequences have the same length.  If the function is None, return a list of                      
    the items of the sequence (or a list of tuples if more than one sequence).     
                                                                                                                            
filter(...)                                                                                                                 
    filter(function or None, sequence) -> list, tuple, or string                                                            
                                                                                                                            
    Return those items of sequence for which function(item) is true.  If                                                    
    function is None, return the items that are true.  If sequence is a tuple                                               
    or string, return the same type, else return a list.     
  
 reduce(...)                                                                     
    reduce(function, sequence[, initial]) -> value                              
                                                                                
    Apply a function of two arguments cumulatively to the items of a sequence,  
    from left to right, so as to reduce the sequence to a single value.         
    For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates           
    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items    
    of the sequence in the calculation, and serves as a default when the        
    sequence is empty.  
    
>>> l= range(1,10)                                                                                                          
>>> f=filter(lambda i: i%2==0,l)                                                                                            
>>> l                                                                                                                       
[1, 2, 3, 4, 5, 6, 7, 8, 9]                                                                                                 
>>> f                                                                                                                       
[2, 4, 6, 8]                                                                                                                
>>> m=map(lambda i: i*i,f)                                                                                                  
>>> m                                                                                                                       
[4, 16, 36, 64]                                                                                                             
>>> r=reduce(lambda total,element: total+element,f)                                                                         
>>> r                                                                                                                       
20                                                                                                                          
>>> r=reduce(lambda total,element: total+element,f,0)                                                                       
>>> r                                                                                                                       
20                                                                                                                          
>>> r=reduce(lambda total,element: total+element,f,10)                                                                      
>>> r                                                                                                                       
30                                                                                                                          
>>> k=[1,2,3,4]                                                                                                             
>>> r1=reduce(lambda total,element: total*element)                                                                          
Traceback (most recent call last):                                                                                          
  File "<stdin>", line 1, in <module>                                                                                       
TypeError: reduce expected at least 2 arguments, got 1                                                                      
>>> r1=reduce(lambda total,element: total*element,k)                                                                        
>>> r1                                                                                                                      
24                                                                                                                          
>>> r1=reduce(lambda total,element: total*element,k,5)                                                                      
>>> r1                                                                                                                      
120                                              
 
 https://spark.apache.org/downloads.html
 https://www.apache.org/dyn/closer.lua/spark/spark-1.6.3/spark-1.6.3-bin-hadoop2.6.tgz
 terminal
 javac -version 
 1.7 or greater
 
 copy from downloads to home in mac
 
 APQYHTD6485432:~ pkum60$ cp ~/Downloads/spark-2.2.0-bin-hadoop2.7.tgz  .
APQYHTD6485432:~ pkum60$ cp ~/Downloads/spark-1.6.3-bin-hadoop2.6.tgz  .
APQYHTD6485432:~ pkum60$ tar xvf spark-1.6.3-bin-hadoop2.6.tgz 
APQYHTD6485432:~ pkum60$ tar xvf spark-2.2.0-bin-hadoop2.7.tgz 
softlink
APQYHTD6485432:~ pkum60$ ln -s spark-1.6.3-bin-hadoop2.6 spark

APQYHTD6485432:~ pkum60$ nano .bash_profile
export SPARK_HOME=/Users/pkum60/spark
export PATH=$PATH:$SPARK_HOME/bin
cntrl+o enter, ctl+x ->nano

APQYHTD6485432:~ pkum60$ . ~/.bash_profile
 APQYHTD6485432:~ pkum60$ spark-shell
 
https://coolestguidesontheplanet.com/add-shell-path-osx/
etc/hadoop/conf: core-site.xml-> can find namenode  in .  details fs.defaultFS
 hdfs-site.xml-> will have blksize and replication info

 
 
 size, block info,replication,
 hadoop fs -du -s -h  s3a://nike-stage/dev/ck/plans/workouts_metadata/downloaded_date=2017-11-27/content/
 hdfs fsck s3a://nike-stage/dev/ck/plans/workouts_metadata/downloaded_date=2017-11-27/content/ -files -blocks -locations
 
 
 yarn-site.xml ->get 
 
 yarn.resourcemanager.webapp.address
 
 etc/spark/conf spark-env.sh
 
 # Options read in YARN client mode
# - HADOOP_CONF_DIR, to point Spark towards Hadoop configuration files
# - SPARK_EXECUTOR_INSTANCES, Number of executors to start (Default: 2)
# - SPARK_EXECUTOR_CORES, Number of cores for the executors (Default: 1).
# - SPARK_EXECUTOR_MEMORY, Memory per Executor (e.g. 1000M, 2G) (Default: 1G)
# - SPARK_DRIVER_MEMORY, Memory for Driver (e.g. 1000M, 2G) (Default: 1G)

 can increase SPARK_EXECUTOR_CORES based on the no of cores we have in cluster and the data being processed
   
  get daily rev of product for closed and completed orders, date asc, rev in desc
  broadcast peoducts and perform lkp in to broadcasted hashmap
  get no of closed and completed orders when data is being filtered
  
  spark-shell --master yarn --conf spark.ui.port=12345
  or
  pyspark --master yarn --conf spark.ui.port=12562
  
  to list all control args
  pyspark --help
  
  pyspark --master yarn --conf spark.ui.port=12562 --num-executors 1 --executors-memory 2G
  to pass control args programmatically 
  
  >>>sc.stop()
  
  from pyspark import SparkConf, SparkContext
  conf1 = SparkConf().setMaster("yarn-client").setAppName("Testing").set("spark.ui.port","12445")
  sc = SparkContext(conf=conf1)
  
  use tracking url and paste in browser to check job details
  
  RDD : data is distributed by dividing the dataset(collection) in to partition based on data and tasks in the memory and is resilient as if something is lost in memory spark will create new task and knows which patition and executes again
  so its recovered so resilient
  
  rdd from collection and file
  
  help(sc)
  
  p=range(1,1000)
  sc.parallelize(p)
  
  read from local file path usin python , this will get list and, splitlines splits bases on newline char
  
  productsRaw = open("/data/retail_db/products/part-00000").read().splitlines()
  productsRaw[0]
  
  
  read file from hdfs
  orders = sc.textFile("user/awsphani/retail_db/orders") ->transformation( map,filter,flatmap,union,
  rders.toDebugString() will give the DAG details when transformations are done
  actions:
  orders.count() ->actions
  orders.collect() will take entire rdd distrubuted at multiple nodes in cluster and create single thread python array at driver,
  normally driver is 1GB and you will face memory issues if the rdd is larger than 1 gb lets say 10 TB
  orders.first() ->returns one element of its datatype here unicode string
  orders.take(5)->returns list of unicode strings
 
  
  after action like count, collect(avoid as possible), take(4) or once job is completed , rdd might get flushed out, to make it persist for using RDD multiple times in same session use as below
  
  from pyspark import StorageLevel
  orders.persists(MEMORY_ONLY or MEMORY_ONLY_SER, DISK_ONLY, MEMORY_AND_DISK,....) 
    or
  orders.cache()->MEMORY_ONLY
  
  get daily rev of product for closed and completed orders, date asc, rev in desc
  broadcast peoducts and perform lkp in to broadcasted hashmap
 
 
########## get no of closed and completed orders when data is being filtered
 
  orders = sc.textFile("user/awsphani/retail_db/orders")
  for order in orders.take(10): print(order)
  //get orders status which is 4th column, indexing start at 0 for lists
  ordersStatuses = orders.map(lambda order: order.split(",")[3])
  ordersStatuses.take(2)
  //get all distict orders status to see what are the orderstatus values
  
  for oderStatus in ordersStatuses.distinct().collect(): print(oderStatus)
  
  //filter for getting only closed and complete
  
  ordersFiltered = orders.filter(lambda order: order.split(",")[3]=="COMPLETE" or order.split(",")[3]=="CLOSED")
  ordersFiltered.count()

########## get no of closed and completed orders using accumulators
  
  ordersCompletedCount=0
  def isComplete(order,ordersCompletedCount):
    isCompleted=order.split(",")[3]=="COMPLETE" or order.split(",")[3]=="CLOSED"
    if(isCompleted):
      ordersCompletedCount+=1
    return ordersCompletedCount  
    
    
  ordersFiltered = orders.filter(lambda order: isComplete(order,ordersCompletedCount))
  ordersFiltered.count() >this will be zero as ordersCompletedCount=0 init is part of driver prgm and lambda is executed at different  executor nodes

so to get this right pass and track , we have to use accumulator

 ordersCompletedCount= sc.accumulator(0)
 ordersCompletedCount.value
 
 def isComplete(order,ordersCompletedCount):
    isCompleted=order.split(",")[3]=="COMPLETE" or order.split(",")[3]=="CLOSED"
    if(isCompleted):
      ordersCompletedCount.add(1)
    return ordersCompletedCount  
  
  ordersFiltered = orders.filter(lambda order: isComplete(order,ordersCompletedCount))
  ordersFiltered.count() >this will return correct value;
  
 ################### for joins we need our data in key value pairs: for orders and orderItems here
  
  key value pairs -> key from orders is order_id and value whatever fields we need, order_date
  
  ordersMap= ordersFiltered.map(lambda order: (int(order.split(",")[0]),order.split(",")[1]))
  ordersMap.first()-> (1,"0171217")
  
  we need order_is as key and tuple of product_id and revenue as value
  orderItems = sc.textFile("user/awsphani/retail_db/order_Items")
  orderItemsMap=orderItems.map(lambda orderItem: (int(orderItem.split(",")[1]),/
  (int(order.splitItem(",")[2]),float(order.splitItem(",")[4]))))
  
  orderItemsMap.first() ->(1,(100, 200.57)
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   



